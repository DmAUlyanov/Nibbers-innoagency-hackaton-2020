{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook contains code for training and feature vectors calculating using recurrent autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, dataloader\n",
    "from statistics import mean\n",
    "import visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionDataset(Dataset):\n",
    "    def __init__(self, dataset_type='train'):\n",
    "        super().__init__()\n",
    "        if dataset_type=='train':\n",
    "            self.filenames = [s.split('.')[0] for s in pd.read_csv('./metrics.csv')['Case'].tolist()]\n",
    "        elif dataset_type=='test':\n",
    "            self.filenames = [s.split('.')[0] for s in pd.read_csv('../Dataset/SecretPart_dummy.csv')['Case'].tolist()]\n",
    "        else:\n",
    "            raise Exception('Unk dataset type!')\n",
    "        self.pred_info = (pd.read_csv('../Dataset/DX_TEST_RESULT_FULL.csv')\n",
    "                          .sort_values(by=['file_name', ' user_name', ' xcenter', ' ycenter']))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames) * 4\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx % len(self.filenames)]\n",
    "        if idx // len(self.filenames) == 0:\n",
    "            user_name = 'Expert'\n",
    "        elif idx // len(self.filenames) == 1:\n",
    "            user_name = 'sample_1'\n",
    "        elif idx // len(self.filenames) == 2:\n",
    "            user_name = 'sample_2'\n",
    "        elif idx // len(self.filenames) == 3:\n",
    "            user_name = 'sample_3'\n",
    "            \n",
    "        info_slice = self.pred_info[self.pred_info['file_name'] == filename][self.pred_info[' user_name'] == user_name]\n",
    "        \n",
    "        res_info = []\n",
    "        for i, row in info_slice.iterrows():\n",
    "            res_info.append([\n",
    "                row[' xcenter'] / 1024,\n",
    "                row[' ycenter'] / 1024,\n",
    "                row[' rhorizontal'] / 1024,\n",
    "                row[' rvertical'] / 1024,\n",
    "            ])\n",
    "            \n",
    "        return np.array(res_info, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GruAutoencoder(nn.Module):\n",
    "    def __init__(self, d_h):\n",
    "        super().__init__()\n",
    "        self.d_h = d_h\n",
    "        self.d_i = 4\n",
    "        self.h_0 = nn.Parameter(torch.randn(1, self.d_h), requires_grad=True)\n",
    "        self.start_token = nn.Parameter(torch.randn(1, self.d_i), requires_grad=True)\n",
    "        self.encoder = nn.GRUCell(self.d_i, self.d_h)\n",
    "        self.out_nn = nn.Linear(self.d_h, self.d_i)\n",
    "        self.decoder = nn.GRUCell(self.d_i, self.d_h)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        r'''\n",
    "        x.size() == [bs, seq_len, d_i]\n",
    "        '''\n",
    "        h_c = self.h_0\n",
    "        for i in range(x.size(1)):\n",
    "            h_c = self.encoder(x[:, i, :], h_c)\n",
    "        \n",
    "        return h_c / torch.norm(h_c, dim=1, keepdim=True)\n",
    "    \n",
    "    def decode(self, h_c, seq_len):\n",
    "        res = []\n",
    "        c_token = self.start_token\n",
    "        for i in range(seq_len):\n",
    "            h_c = self.decoder(c_token, h_c)\n",
    "            c_token = self.out_nn(h_c)\n",
    "            res.append(c_token)\n",
    "        return torch.stack(res, dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        encoded = self.encode(x)\n",
    "        decoded = self.decode(encoded, seq_len)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PredictionDataset()\n",
    "train_loader = dataloader.DataLoader(train_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GruAutoencoder(16)\n",
    "model_opt = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "vis = visdom.Visdom(env='Seq autoencoder train (1)')\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./ae_model.pth'))\n",
    "model_opt.load_state_dict(torch.load('./ae_model_opt.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dmitry\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(300):\n",
    "    for batch in train_loader:\n",
    "        seq_len = batch.size(1)\n",
    "        if seq_len > 0:\n",
    "            model_opt.zero_grad()\n",
    "            prediction = model(batch)\n",
    "            loss = nn.functional.mse_loss(prediction, batch, reduction='sum')\n",
    "            loss.backward()\n",
    "            model_opt.step()\n",
    "\n",
    "            losses.append(loss.detach().item() / seq_len)\n",
    "\n",
    "            if step % 20 == 0:\n",
    "                vis.line(X=[step], Y=[mean(losses)], update='append', name='total loss', win='losses')\n",
    "                losses = []\n",
    "\n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './ae_model.pth')\n",
    "torch.save(model_opt.state_dict(), './ae_model_opt.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_idx = {fn: i for i, fn in enumerate(train_dataset.filenames)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case</th>\n",
       "      <th>Sample 1</th>\n",
       "      <th>Sample 2</th>\n",
       "      <th>Sample 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000072_000.png</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000150_002.png</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000181_061.png</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000211_019.png</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000211_041.png</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Case  Sample 1  Sample 2  Sample 3\n",
       "0  00000072_000.png         1         5         1\n",
       "1  00000150_002.png         5         5         3\n",
       "2  00000181_061.png         4         4         3\n",
       "3  00000211_019.png         4         4         2\n",
       "4  00000211_041.png         3         5         2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marks = pd.read_csv('../Dataset/OpenPart.csv')\n",
    "marks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dmitry\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "r'''\n",
    "Calculate feature vectors for predictions in dataset\n",
    "'''\n",
    "\n",
    "vectors = dict()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, row in marks.iterrows():\n",
    "        fname = row['Case'].split('.')[0]\n",
    "\n",
    "        pred_exp = train_dataset[rev_idx[fname]]\n",
    "        pred_1 = train_dataset[rev_idx[fname] + len(train_dataset.filenames)]\n",
    "        pred_2 = train_dataset[rev_idx[fname] + 2 * len(train_dataset.filenames)]\n",
    "        pred_3 = train_dataset[rev_idx[fname] + 3 * len(train_dataset.filenames)]\n",
    "        \n",
    "        feature_exp = model.encode(torch.tensor(pred_exp).unsqueeze(0)).numpy()\n",
    "        feature_1 = model.encode(torch.tensor(pred_1).unsqueeze(0)).numpy()\n",
    "        feature_2 = model.encode(torch.tensor(pred_2).unsqueeze(0)).numpy()\n",
    "        feature_3 = model.encode(torch.tensor(pred_3).unsqueeze(0)).numpy()\n",
    "        \n",
    "        vectors[fname] = [feature_exp, feature_1, feature_2, feature_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./vectors.pickle', 'wb') as vec_file:\n",
    "    pickle.dump(vectors, vec_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 00000072_000.png\n",
      "Sample 1: 1 / -0.06276200711727142\n",
      "Sample 2: 5 / 0.9999997615814209\n",
      "Sample 3: 1 / -0.07965496182441711\n",
      "---------------------------------------\n",
      "File 00000150_002.png\n",
      "Sample 1: 5 / 0.9996593594551086\n",
      "Sample 2: 5 / 0.9980742931365967\n",
      "Sample 3: 3 / 0.9852204918861389\n",
      "---------------------------------------\n",
      "File 00000181_061.png\n",
      "Sample 1: 4 / 0.9256361722946167\n",
      "Sample 2: 4 / 0.9171059131622314\n",
      "Sample 3: 3 / 0.3865862190723419\n",
      "---------------------------------------\n",
      "File 00000211_019.png\n",
      "Sample 1: 4 / 0.9019522666931152\n",
      "Sample 2: 4 / 0.9366953372955322\n",
      "Sample 3: 2 / 0.4156748354434967\n",
      "---------------------------------------\n",
      "File 00000211_041.png\n",
      "Sample 1: 3 / 0.4643249213695526\n",
      "Sample 2: 5 / 0.8481517434120178\n",
      "Sample 3: 2 / 0.4721382260322571\n",
      "---------------------------------------\n",
      "File 00000344_003.png\n",
      "Sample 1: 2 / -0.3441147208213806\n",
      "Sample 2: 3 / 0.22616490721702576\n",
      "Sample 3: 1 / 0.9749670624732971\n",
      "---------------------------------------\n",
      "File 00000468_033.png\n",
      "Sample 1: 2 / -0.5890181660652161\n",
      "Sample 2: 5 / 0.9997100234031677\n",
      "Sample 3: 5 / 0.9999647736549377\n",
      "---------------------------------------\n",
      "File 00000808_002.png\n",
      "Sample 1: 2 / 0.34496453404426575\n",
      "Sample 2: 3 / 0.36735329031944275\n",
      "Sample 3: 3 / 0.3703496754169464\n",
      "---------------------------------------\n",
      "File 00000830_000.png\n",
      "Sample 1: 3 / 0.019690051674842834\n",
      "Sample 2: 3 / 0.5106195211410522\n",
      "Sample 3: 3 / 0.06242762506008148\n",
      "---------------------------------------\n",
      "File 00000974_002.png\n",
      "Sample 1: 1 / -0.11897951364517212\n",
      "Sample 2: 4 / 0.9768686294555664\n",
      "Sample 3: 1 / -0.11897951364517212\n",
      "---------------------------------------\n",
      "File 00001075_024.png\n",
      "Sample 1: 3 / 0.928617000579834\n",
      "Sample 2: 2 / 0.8263108730316162\n",
      "Sample 3: 3 / 0.32379454374313354\n",
      "---------------------------------------\n",
      "File 00001187_006.png\n",
      "Sample 1: 2 / 0.5573118925094604\n",
      "Sample 2: 1 / -0.1256353259086609\n",
      "Sample 3: 1 / -0.1256353259086609\n",
      "---------------------------------------\n",
      "File 00002350_001.png\n",
      "Sample 1: 5 / 0.9997161626815796\n",
      "Sample 2: 3 / 0.3938399851322174\n",
      "Sample 3: 3 / 0.3955758213996887\n",
      "---------------------------------------\n",
      "File 00002578_000.png\n",
      "Sample 1: 4 / 0.8996790647506714\n",
      "Sample 2: 3 / 0.6782932281494141\n",
      "Sample 3: 2 / 0.12677162885665894\n",
      "---------------------------------------\n",
      "File 00002583_014.png\n",
      "Sample 1: 4 / 0.908776581287384\n",
      "Sample 2: 4 / 0.9979325532913208\n",
      "Sample 3: 3 / 0.6753764152526855\n",
      "---------------------------------------\n",
      "File 00002597_000.png\n",
      "Sample 1: 5 / 0.9999997615814209\n",
      "Sample 2: 4 / -0.11634930968284607\n",
      "Sample 3: 5 / 0.9999997615814209\n",
      "---------------------------------------\n",
      "File 00002706_004.png\n",
      "Sample 1: 1 / -0.1111149936914444\n",
      "Sample 2: 1 / 0.9360427260398865\n",
      "Sample 3: 1 / -0.1111149936914444\n",
      "---------------------------------------\n",
      "File 00002711_000.png\n",
      "Sample 1: 5 / 0.8882687091827393\n",
      "Sample 2: 3 / 0.8170771598815918\n",
      "Sample 3: 3 / 0.30000337958335876\n",
      "---------------------------------------\n",
      "File 00002763_031.png\n",
      "Sample 1: 4 / 0.7751220464706421\n",
      "Sample 2: 4 / 0.7697171568870544\n",
      "Sample 3: 2 / 0.22003118693828583\n",
      "---------------------------------------\n",
      "File 00002856_009.png\n",
      "Sample 1: 2 / -0.19464798271656036\n",
      "Sample 2: 2 / 0.28585702180862427\n",
      "Sample 3: 5 / 0.9979323148727417\n",
      "---------------------------------------\n",
      "File 00002980_000.png\n",
      "Sample 1: 5 / 0.4873389005661011\n",
      "Sample 2: 5 / 0.997590184211731\n",
      "Sample 3: 5 / 0.4997352361679077\n",
      "---------------------------------------\n",
      "File 00003072_028.png\n",
      "Sample 1: 2 / 0.9231891632080078\n",
      "Sample 2: 2 / 0.7140085697174072\n",
      "Sample 3: 3 / -0.040853410959243774\n",
      "---------------------------------------\n",
      "File 00003333_002.png\n",
      "Sample 1: 3 / 0.3670095205307007\n",
      "Sample 2: 5 / 0.9995124936103821\n",
      "Sample 3: 5 / 0.9984762072563171\n",
      "---------------------------------------\n",
      "File 00003391_001.png\n",
      "Sample 1: 3 / 0.9222203493118286\n",
      "Sample 2: 3 / 0.8039060235023499\n",
      "Sample 3: 1 / 0.5566577911376953\n",
      "---------------------------------------\n",
      "File 00003400_003.png\n",
      "Sample 1: 3 / 0.7254327535629272\n",
      "Sample 2: 2 / 0.4000551998615265\n",
      "Sample 3: 2 / -0.10105793923139572\n",
      "---------------------------------------\n",
      "File 00003787_003.png\n",
      "Sample 1: 3 / -0.017361611127853394\n",
      "Sample 2: 5 / 0.9996206164360046\n",
      "Sample 3: 5 / 0.9989954829216003\n",
      "---------------------------------------\n",
      "File 00003894_005.png\n",
      "Sample 1: 5 / 0.9917594194412231\n",
      "Sample 2: 5 / 0.9881091713905334\n",
      "Sample 3: 5 / 0.9988519549369812\n",
      "---------------------------------------\n",
      "File 00003973_008.png\n",
      "Sample 1: 1 / 0.9196051955223083\n",
      "Sample 2: 3 / 0.4183003604412079\n",
      "Sample 3: 3 / 0.43531498312950134\n",
      "---------------------------------------\n",
      "File 00004808_090.png\n",
      "Sample 1: 4 / 0.8164931535720825\n",
      "Sample 2: 5 / 0.9864462614059448\n",
      "Sample 3: 3 / 0.3824366629123688\n",
      "---------------------------------------\n",
      "File 00004911_018.png\n",
      "Sample 1: 4 / 0.6673388481140137\n",
      "Sample 2: 4 / 0.6660481691360474\n",
      "Sample 3: 4 / 0.667650580406189\n",
      "---------------------------------------\n",
      "File 00005089_014.png\n",
      "Sample 1: 4 / 0.8553855419158936\n",
      "Sample 2: 1 / 0.3183942437171936\n",
      "Sample 3: 4 / 0.526835024356842\n",
      "---------------------------------------\n",
      "File 00005215_000.png\n",
      "Sample 1: 5 / 0.9999997615814209\n",
      "Sample 2: 1 / -0.09655067324638367\n",
      "Sample 3: 5 / 0.9999997615814209\n",
      "---------------------------------------\n",
      "File 00005353_000.png\n",
      "Sample 1: 5 / 0.10790912806987762\n",
      "Sample 2: 5 / 0.28145208954811096\n",
      "Sample 3: 4 / 0.23297621309757233\n",
      "---------------------------------------\n",
      "File 00006323_009.png\n",
      "Sample 1: 2 / -0.061602264642715454\n",
      "Sample 2: 4 / 0.6289081573486328\n",
      "Sample 3: 1 / -0.09913823008537292\n",
      "---------------------------------------\n",
      "File 00006948_002.png\n",
      "Sample 1: 4 / 0.8388400673866272\n",
      "Sample 2: 3 / 0.7202895283699036\n",
      "Sample 3: 2 / 0.5465144515037537\n",
      "---------------------------------------\n",
      "File 00007034_016.png\n",
      "Sample 1: 1 / -0.10952667146921158\n",
      "Sample 2: 5 / -0.07021285593509674\n",
      "Sample 3: 1 / 0.8244603872299194\n",
      "---------------------------------------\n",
      "File 00007558_006.png\n",
      "Sample 1: 3 / 0.18329304456710815\n",
      "Sample 2: 1 / 0.8574589490890503\n",
      "Sample 3: 1 / -0.01188020408153534\n",
      "---------------------------------------\n",
      "File 00007882_001.png\n",
      "Sample 1: 4 / 0.9181511402130127\n",
      "Sample 2: 5 / 0.9081119894981384\n",
      "Sample 3: 2 / 0.16422073543071747\n",
      "---------------------------------------\n",
      "File 00008008_027.png\n",
      "Sample 1: 2 / 0.8620553016662598\n",
      "Sample 2: 4 / 0.4058506488800049\n",
      "Sample 3: 2 / -0.2467772513628006\n",
      "---------------------------------------\n",
      "File 00008386_000.png\n",
      "Sample 1: 2 / 0.2465660572052002\n",
      "Sample 2: 5 / 0.9997994899749756\n",
      "Sample 3: 4 / 0.9993863105773926\n",
      "---------------------------------------\n",
      "File 00008547_001.png\n",
      "Sample 1: 3 / 0.7748364210128784\n",
      "Sample 2: 2 / 0.08914266526699066\n",
      "Sample 3: 2 / -0.5151804685592651\n",
      "---------------------------------------\n",
      "File 00008554_009.png\n",
      "Sample 1: 2 / 0.08480784296989441\n",
      "Sample 2: 5 / 0.9968474507331848\n",
      "Sample 3: 5 / 0.9929943084716797\n",
      "---------------------------------------\n",
      "File 00008814_010.png\n",
      "Sample 1: 2 / 0.23832161724567413\n",
      "Sample 2: 2 / 0.4001653790473938\n",
      "Sample 3: 1 / -0.18805214762687683\n",
      "---------------------------------------\n",
      "File 00009368_006.png\n",
      "Sample 1: 4 / 0.6672430038452148\n",
      "Sample 2: 4 / 0.6029388904571533\n",
      "Sample 3: 2 / 0.27123329043388367\n",
      "---------------------------------------\n",
      "File 00009437_008.png\n",
      "Sample 1: 5 / 0.8492564558982849\n",
      "Sample 2: 5 / 0.9958479404449463\n",
      "Sample 3: 3 / 0.4800593852996826\n",
      "---------------------------------------\n",
      "File 00009507_004.png\n",
      "Sample 1: 3 / 0.272411048412323\n",
      "Sample 2: 5 / 0.9992047548294067\n",
      "Sample 3: 5 / 0.9997632503509521\n",
      "---------------------------------------\n",
      "File 00009619_000.png\n",
      "Sample 1: 5 / 0.9093817472457886\n",
      "Sample 2: 5 / 0.9988529682159424\n",
      "Sample 3: 2 / 0.24110163748264313\n",
      "---------------------------------------\n",
      "File 00010060_038.png\n",
      "Sample 1: 2 / -0.017415106296539307\n",
      "Sample 2: 1 / 0.2969159185886383\n",
      "Sample 3: 1 / -0.07919812202453613\n",
      "---------------------------------------\n",
      "File 00010103_014.png\n",
      "Sample 1: 5 / 0.9921334981918335\n",
      "Sample 2: 3 / 0.2637949585914612\n",
      "Sample 3: 1 / 0.20891207456588745\n",
      "---------------------------------------\n",
      "File 00010277_000.png\n",
      "Sample 1: 3 / 0.32392045855522156\n",
      "Sample 2: 4 / 0.909640908241272\n",
      "Sample 3: 4 / -0.11911839246749878\n",
      "---------------------------------------\n",
      "File 00010381_000.png\n",
      "Sample 1: 3 / 0.7184053659439087\n",
      "Sample 2: 1 / -0.10364660620689392\n",
      "Sample 3: 3 / 0.4809046983718872\n",
      "---------------------------------------\n",
      "File 00010447_018.png\n",
      "Sample 1: 3 / 0.667370080947876\n",
      "Sample 2: 3 / 0.3687897026538849\n",
      "Sample 3: 3 / 0.3881211578845978\n",
      "---------------------------------------\n",
      "File 00010815_006.png\n",
      "Sample 1: 4 / 0.3600413501262665\n",
      "Sample 2: 4 / 0.3652228116989136\n",
      "Sample 3: 5 / 0.06600043177604675\n",
      "---------------------------------------\n",
      "File 00010936_016.png\n",
      "Sample 1: 2 / -0.2491263747215271\n",
      "Sample 2: 5 / 0.9996140599250793\n",
      "Sample 3: 1 / 0.9308049082756042\n",
      "---------------------------------------\n",
      "File 00011157_001.png\n",
      "Sample 1: 4 / 0.865044891834259\n",
      "Sample 2: 5 / 0.9253566265106201\n",
      "Sample 3: 2 / -0.5278447866439819\n",
      "---------------------------------------\n",
      "File 00011237_006.png\n",
      "Sample 1: 3 / -0.3632931709289551\n",
      "Sample 2: 1 / -0.15213564038276672\n",
      "Sample 3: 5 / 0.9848095774650574\n",
      "---------------------------------------\n",
      "File 00011269_019.png\n",
      "Sample 1: 1 / 0.20715241134166718\n",
      "Sample 2: 3 / 0.26989978551864624\n",
      "Sample 3: 1 / 0.06327000260353088\n",
      "---------------------------------------\n",
      "File 00011355_011.png\n",
      "Sample 1: 4 / 0.6261087656021118\n",
      "Sample 2: 5 / 0.94511878490448\n",
      "Sample 3: 3 / 0.6670839786529541\n",
      "---------------------------------------\n",
      "File 00011450_000.png\n",
      "Sample 1: 4 / 0.6207153797149658\n",
      "Sample 2: 4 / 0.36332058906555176\n",
      "Sample 3: 3 / 0.3402986526489258\n",
      "---------------------------------------\n",
      "File 00011502_001.png\n",
      "Sample 1: 5 / 0.9999997615814209\n",
      "Sample 2: 1 / -0.10852120816707611\n",
      "Sample 3: 1 / -0.10276341438293457\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "r'''\n",
    "Compare scores and cosine similarity between expert and model feature vector\n",
    "'''\n",
    "\n",
    "for i, row in marks.iterrows():\n",
    "    fname = row['Case'].split('.')[0]    \n",
    "    print(f'File {row[\"Case\"]}')\n",
    "    print(f'Sample 1: {row[\"Sample 1\"]} / {(vectors[fname][0] * vectors[fname][1]).sum().item()}')\n",
    "    print(f'Sample 2: {row[\"Sample 2\"]} / {(vectors[fname][0] * vectors[fname][2]).sum().item()}')\n",
    "    print(f'Sample 3: {row[\"Sample 3\"]} / {(vectors[fname][0] * vectors[fname][3]).sum().item()}')\n",
    "    print('---------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'00011827_003'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-b1808d097758>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Case'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mpred_exp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrev_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mpred_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrev_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mpred_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrev_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '00011827_003'"
     ]
    }
   ],
   "source": [
    "test_dataset = \n",
    "with torch.no_grad():\n",
    "    for i, row in pd.read_csv('../Dataset/SecretPart_dummy.csv').iterrows():\n",
    "        fname = row['Case'].split('.')[0]\n",
    "\n",
    "        pred_exp = train_dataset[rev_idx[fname]]\n",
    "        pred_1 = train_dataset[rev_idx[fname] + len(train_dataset.filenames)]\n",
    "        pred_2 = train_dataset[rev_idx[fname] + 2 * len(train_dataset.filenames)]\n",
    "        pred_3 = train_dataset[rev_idx[fname] + 3 * len(train_dataset.filenames)]\n",
    "        \n",
    "        feature_exp = model.encode(torch.tensor(pred_exp).unsqueeze(0)).numpy()\n",
    "        feature_1 = model.encode(torch.tensor(pred_1).unsqueeze(0)).numpy()\n",
    "        feature_2 = model.encode(torch.tensor(pred_2).unsqueeze(0)).numpy()\n",
    "        feature_3 = model.encode(torch.tensor(pred_3).unsqueeze(0)).numpy()\n",
    "        \n",
    "        vectors[fname] = [feature_exp, feature_1, feature_2, feature_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
